---
title: "Simuations for rankLasso"
output: html_notebook
---

## Data Generation

```{r}

n<-c(100,200,300,400) #number of samples
p<-c(100,400,900,1600) #number of variables
p_0<-c(3,10,20) #number of true variables

```

### Scenario 1

$$Y = X\beta + \epsilon$$


Design matrix, X is generated from multivariate normal distribution with covariance matrix as Identity matrix and true coefficients are $\beta_{1}=\beta_{2}=...\beta_{p_{0}}=3$. $\epsilon$ is generated from standard cauchy distribution

```{r}
rmvn <- function(n, mu=0, V = matrix(1)){
  p <- length(mu)
  if(any(is.na(match(dim(V),p))))
    stop("Dimension problem!")
  D <- chol(V)
  (matrix(rnorm(n*p), ncol=p)%*%D + rep(mu,rep(n,p)))
}

':=' <- function(lhs, rhs) {
  frame <- parent.frame()
  lhs <- as.list(substitute(lhs))
  if (length(lhs) > 1)
    lhs <- lhs[-1]
  if (length(lhs) == 1) {
    do.call(`=`, list(lhs[[1]], rhs), envir=frame)
    return(invisible(NULL)) 
  }
  if (is.function(rhs) || is(rhs, 'formula'))
    rhs <- list(rhs)
  if (length(lhs) > length(rhs))
    rhs <- c(rhs, rep(list(NULL), length(lhs) - length(rhs)))
  for (i in 1:length(lhs))
    do.call(`=`, list(lhs[[i]], rhs[[i]]), envir=frame)
  return(invisible(NULL)) 
}


data_gen_1<-function(n,p,p_0)
{
  X<-rmvn(n,rep(0,p),diag(p))
  beta<-c(rep(3,p_0),rep(0,p-p_0))
  ep<-rcauchy(n,0,1)
  Y=X%*%beta + ep
  return(list(X,beta,Y))
}

X=matrix(data=NA,n[1],n[1])
beta=rep(NA,p[1])
Y=rep(NA,n[1])
c(X,beta,Y):=data_gen_1(100,5,3)
```

###  Scenrario 3

```{r}

data_gen_2<-function(n,p,p_0)
{
  ma<-matrix(data=0.3,nrow=p,ncol = p)
  diag(ma)<-rep(1,p)
  X<-rmvn(n,rep(0,p),ma)
  beta<-c(rep(3,p_0),rep(0,p-p_0))
  ep<-rcauchy(n,0,1)
  Y=X%*%beta + ep
  return(list(X,beta,Y))
}

X=matrix(data=NA,n[1],n[1])
beta=rep(NA,p[1])
Y=rep(NA,n[1])
c(X,beta,Y):=data_gen_2(100,5,3)

```




## Implimentation

### RankLasso-1
```{r}
library(glmnet)

lambda_rl<-function(p,n){
  return(0.3*sqrt(log(p)/n))
}

fp_rl<-rep(0,200)
fn_rl<-rep(0,200)
tp_rl<-rep(0,200)
nmp<-rep(0,4)
fdr<-rep(0,4)
power<-rep(0,4)
for(i in 1:4)
 {
  print(i)
  for (j in 1:200)
    {
      X=matrix(data=NA,n[k],n[k])
      beta=rep(NA,p[k])
      Y=rep(NA,n[k])
      c(X,beta,Y):=data_gen_1(n[k],p[k],3)
      
      # model<-glmnet(X,Y,family = "gaussian",lambda = lambda_rl(p[k],n[k]),intercept = FALSE)
      model<-cv.glmnet(X,rank(Y)/n[k],family="gaussian")
      beta_est<-model$glmnet.fit$beta[,model$index[1]]
      fp_rl[j]<-sum(beta_est[4:p[k]]!=beta[4:p[k]])
      fn_rl[j]<-sum(beta_est[1:3]==0)
      tp_rl[j]<-sum(beta_est[1:3]!=0)
  
    }
  nmp[i]<-mean(fp_rl+fn_rl)
  fdr[i]<-mean(fp_rl/(fp_rl+tp_rl))
  power[i]<-mean(tp_rl[j]/3)
 }



model$beta


```

### Lasso with CV-1

```{r}
fp_lasso<-rep(0,200)
fn_lasso<-rep(0,200)
tp_lasso<-rep(0,200)
nmp_lasso<-rep(0,4)
fdr_lasso<-rep(0,4)
power_lasso<-rep(0,4)
for(i in 1:4)
 {
  print(i)
  for (j in 1:200)
    {
      X=matrix(data=NA,n[k],n[k])
      beta=rep(NA,p[k])
      Y=rep(NA,n[k])
      c(X,beta,Y):=data_gen_1(n[k],p[k],3)
      
      # model<-glmnet(X,Y,family = "gaussian",lambda = lambda_rl(p[k],n[k]),intercept = FALSE)
      model<-cv.glmnet(X,Y,family="gaussian")
      beta_est<-model$glmnet.fit$beta[,model$index[1]]
      fp_lasso[j]<-sum(beta_est[4:p[k]]!=beta[4:p[k]])
      fn_lasso[j]<-sum(beta_est[1:3]==0)
      tp_lasso[j]<-sum(beta_est[1:3]!=0)
  
    }
  nmp_lasso[i]<-mean(fp_lasso+fn_lasso)
  fdr_lasso[i]<-mean(fp_lasso/(fp_lasso+tp_lasso))
  power_lasso[i]<-mean(tp_lasso[j]/3)
 }


```

